{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366fbfdd",
   "metadata": {},
   "source": [
    "# Program Overview\n",
    "\n",
    "The purpose of this notebook is to acquire the raw data necessary to analyze monthly article traffic from English Wikipedia articles published 07-01-2015 through 09-30-2023.\n",
    "\n",
    "The source data uses the following license:\n",
    "**EKRC INSERT LICENSE HERE\n",
    "\n",
    "We also use the Wikimedia Foundation REST API which has the following\n",
    "terms of use:\n",
    "https://www.mediawiki.org/wiki/REST_API#Terms_and_conditions\n",
    "\n",
    "The Pageviews API documentation can be found at the following link:\n",
    "https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews\n",
    "\n",
    "We will leverage code developed by Dr. David W. McDonald for use in Data 512  which is provided under Creative Commons CC-BY license. (https://creativecommons.org/ and https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "Additionally, we will be using a list of Academy Award winning article titles provided by Dr. McDonald. A link to the list can be found here: https://drive.google.com/drive/folders/1lPJF73GX5Vyu2uAvT5VpAY-xGwP2fCCx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6964bee",
   "metadata": {},
   "source": [
    "## API Pull Setup\n",
    "\n",
    "The following sections of code will create a method to call the Pageviews API. The code was taken from Dr. McDonald's scripts noted in the Program Overview section above. Limited changes were made to lower-case variable names, update the range of dates for information pulls, and to limit line length where possible.\n",
    "\n",
    "We begin by importing the necessary Python libraries. Users may not have \"requests\" installed, and can use pip to add it to their machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17dc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import python libraries\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d981ecd",
   "metadata": {},
   "source": [
    "The following code will create constants leveraged in the API calls in addition to a list of test article titles to verify the code is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dca299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of constants leveraged in API calls\n",
    "\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "api_request_pageviews_endpoint = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "api_request_per_article_params = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "api_latency_assumed = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "api_throttle_wait = (1.0/100.0)-api_latency_assumed\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include your email address which will allow them\n",
    "# to contact you if something happens - such as - your code exceeding rate limits - or some other error \n",
    "request_headers = {\n",
    "    'User-Agent': 'ekrolen@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "ex_article_titles = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. \n",
    "# The dictionary has a field/key for each of the required parameters. In the example, below, we only vary the article name,\n",
    "# so the majority of the fields can stay constant for each request. Of course, these values *could* be changed if necessary.\n",
    "article_pageviews_params_template = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015070100\",   # July 1, 2015 in YYYYMMDDHH format\n",
    "    \"end\":         \"2023093000\"    # September 30, 2023 in YYYYMMDDHH format\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764cc9a8",
   "metadata": {},
   "source": [
    "As described in Dr. McDonald's code, \"The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992d7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the api request \n",
    "\n",
    "def request_pageviews_per_article(article_title = None, \n",
    "                                  access_method = None,\n",
    "                                  endpoint_url = api_request_pageviews_endpoint, \n",
    "                                  endpoint_params = api_request_per_article_params,\n",
    "                                  request_template = article_pageviews_params_template,\n",
    "                                  headers = request_headers):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    #Access method can also be a parameter in the call or in the request_template\n",
    "    if access_method:\n",
    "        request_template['access'] = access_method\n",
    "    \n",
    "    if not request_template['access']:\n",
    "        raise Exception(\"Must supply an access method ('desktop', 'mobile-app', or 'mobile-web') to make a pageviews request.\")\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if api_throttle_wait > 0.0:\n",
    "            time.sleep(api_throttle_wait)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075e08b",
   "metadata": {},
   "source": [
    "The following code can be uncommented to verify the API call is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3957348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Getting pageview data for: \",ex_article_titles[1])\\nviews = request_pageviews_per_article(ex_article_titles[1], \"mobile-app\")\\n\\n#print(json.dumps(views,indent=4))\\nprint(\"Have %d months of pageview data\"%(len(views[\\'items\\'])))\\nfor month in views[\\'items\\']:\\n    print(json.dumps(month,indent=4))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(\"Getting pageview data for: \",ex_article_titles[1])\n",
    "views = request_pageviews_per_article(ex_article_titles[1], \"mobile-app\")\n",
    "\n",
    "#print(json.dumps(views,indent=4))\n",
    "print(\"Have %d months of pageview data\"%(len(views['items'])))\n",
    "for month in views['items']:\n",
    "    print(json.dumps(month,indent=4))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60b7bc",
   "metadata": {},
   "source": [
    "The following section of code will build the list of articles we want to retrieve data for. See the Program Overview section for more information on the source of this list. \n",
    "\n",
    "thank_the_academy.AUG.2023.csv should be downloaded from https://docs.google.com/spreadsheets/d/1A1h_7KAo7KXaVxdScJmIVPTvjb3IuY9oZhNV4ZHxrxw/edit#gid=1229854301 and saved to this repository's \"raw_data\" directory before running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efd78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the csv\n",
    "article_title_list = pd.read_csv('../raw_data/thank_the_academy.AUG.2023.csv')\n",
    "\n",
    "#Save the names as a list\n",
    "article_titles = list(article_title_list['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ce6b2",
   "metadata": {},
   "source": [
    "## Acquire monthly mobile app access data\n",
    "\n",
    "The following section of code will acquire monthly mobile app access data using the request_pageviews_per_article method and list of article titles built previously. The outputs are stored in a dictionary where the key is the article name (movie title) and the values are the timeseries data as returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293c98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1359 have been written\n",
      "10 of 1359 have been written\n"
     ]
    }
   ],
   "source": [
    "#Pulling the monthly mobile-app views for each article in the list\n",
    "mobile_app_dict = {}\n",
    "missing_titles = []\n",
    "for i in range(len(article_titles)):\n",
    "    if '/' in article_titles[i]:\n",
    "        missing_titles.append(article_titles[i])\n",
    "    else:\n",
    "        views = request_pageviews_per_article(article_titles[i], 'mobile-app')\n",
    "        mobile_app_dict[article_titles[i]] = views['items']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f04c5e",
   "metadata": {},
   "source": [
    "Next we will print out any article titles which could not be parsed by the Pageviews API due to a \"/\" present in their name. These articles will be omitted from our analysis as their information cannot be pulled using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae584e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\")\n",
    "print(missing_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709bee6e",
   "metadata": {},
   "source": [
    "We will now save the mobile-app pageview information in a JSON for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making mobile_app_json a JSON\n",
    "mobile_app_json_object = json.dumps(mobile_app_dict, indent = 4) \n",
    "\n",
    "#Writing to the file\n",
    "with open('../raw_data/mobile_app_pageviews.json', 'w') as outfile:\n",
    "    outfile.write(mobile_app_json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1ac19",
   "metadata": {},
   "source": [
    "The following code verifies that the user got the full number of expected articles from the pageviews app, minus the ones which could not be pulled due to a \"/\" in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing if the # of keys in the mobile_app_json is equal to the number of article titles minus the titles which\n",
    "#could not be pulled\n",
    "if len(mobile_app_json.keys()) == len(article_titles) - len(missing_titles):\n",
    "    print(\"Correct number of articles captured in pageviews.\")\n",
    "else:\n",
    "    print(\"ERROR - wrong number of articles captured in pageviews. Expecting \"+str(len(article_titles) - len(missing_titles))+\n",
    "         \" and got: \"+str(len(mobile_app_json.keys()))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466c5c5",
   "metadata": {},
   "source": [
    "## Acquire monthly mobile web access data\n",
    "\n",
    "The following section of code will acquire monthly mobile web access data using the request_pageviews_per_article method and list of article titles built previously. The outputs are stored in a dictionary where the key is the article name (movie title) and the values are the timeseries data as returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850b74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling the monthly mobile-web views for each article in the list\n",
    "mobile_web_dict = {}\n",
    "missing_mobile_web_titles = []\n",
    "for i in range(len(article_titles)):\n",
    "    if '/' in article_titles[i]:\n",
    "        missing_mobile_web_titles.append(article_titles[i])\n",
    "    else:\n",
    "        views = request_pageviews_per_article(article_titles[i], 'mobile-web')\n",
    "        mobile_web_dict[article_titles[i]] = views['items']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34baa3f3",
   "metadata": {},
   "source": [
    "Next we will print out any article titles which could not be parsed by the Pageviews API due to a \"/\" present in their name. These articles will be omitted from our analysis as their information cannot be pulled using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21726254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\")\n",
    "print(missing_mobile_web_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c92d0a",
   "metadata": {},
   "source": [
    "We will now save the mobile-web pageview information in a JSON for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e94249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making mobile_web_json a JSON\n",
    "mobile_web_json_object = json.dumps(mobile_web_dict, indent = 4) \n",
    "\n",
    "#Writing to the file\n",
    "with open('../raw_data/mobile_web_pageviews.json', 'w') as outfile:\n",
    "    outfile.write(mobile_web_json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05422585",
   "metadata": {},
   "source": [
    "The following code verifies that the user got the full number of expected articles from the pageviews app, minus the ones which could not be pulled due to a \"/\" in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebce72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing if the # of keys in the mobile_web_dict is equal to the number of article titles minus the titles which\n",
    "#could not be pulled\n",
    "if len(mobile_web_dict.keys()) == len(article_titles) - len(missing_mobile_web_titles):\n",
    "    print(\"Correct number of articles captured in pageviews.\")\n",
    "else:\n",
    "    print(\"ERROR - wrong number of articles captured in pageviews. Expecting \"+\n",
    "          str(len(article_titles) - len(missing_mobile_web_titles))+\" and got: \"+str(len(mobile_web_dict.keys()))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3bd59",
   "metadata": {},
   "source": [
    "## Acquire desktop access data\n",
    "\n",
    "The following section of code will acquire monthly desktop access data using the request_pageviews_per_article method and list of article titles built previously. The outputs are stored in a dictionary where the key is the article name (movie title) and the values are the timeseries data as returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31bfb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Pulling the monthly desktop views for each article in the list\n",
    "desktop_dict = {}\n",
    "missing_desktop_titles = []\n",
    "for i in range(len(article_titles)):\n",
    "    if '/' in article_titles[i]:\n",
    "        missing_desktop_titles.append(article_titles[i])\n",
    "    else:\n",
    "        views = request_pageviews_per_article(article_titles[i], 'desktop')\n",
    "        desktop_dict[article_titles[i]] = views['items']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be300c52",
   "metadata": {},
   "source": [
    "Next we will print out any article titles which could not be parsed by the Pageviews API due to a \"/\" present in their name. These articles will be omitted from our analysis as their information cannot be pulled using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\")\n",
    "print(missing_desktop_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a7d4c",
   "metadata": {},
   "source": [
    "We will now save the desktop pageview information in a JSON for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4becc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making desktop_json a JSON\n",
    "desktop_json_object = json.dumps(desktop_dict, indent = 4) \n",
    "\n",
    "#Writing to the file\n",
    "with open('../raw_data/desktop_pageviews.json', 'w') as outfile:\n",
    "    outfile.write(desktop_json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20768c",
   "metadata": {},
   "source": [
    "The following code verifies that the user got the full number of expected articles from the pageviews app, minus the ones which could not be pulled due to a \"/\" in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d0ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing if the # of keys in the desktop_dict is equal to the number of article titles minus the titles which\n",
    "#could not be pulled\n",
    "if len(desktop_dict.keys()) == len(article_titles) - len(missing_desktop_titles):\n",
    "    print(\"Correct number of articles captured in pageviews.\")\n",
    "else:\n",
    "    print(\"ERROR - wrong number of articles captured in pageviews. Expecting \"+\n",
    "          str(len(article_titles) - len(missing_desktop_titles))+\" and got: \"+str(len(desktop_dict.keys()))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
