{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366fbfdd",
   "metadata": {},
   "source": [
    "# Program Overview\n",
    "\n",
    "The purpose of this notebook is to acquire the raw data necessary to analyze monthly article traffic from English Wikipedia articles published 07-01-2015 through 09-30-2023.\n",
    "\n",
    "The source data comes from English Wikipedia, the text of which is licensed under \"Creative Commons Attribution Share-Alike license\" (https://en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License)\n",
    "\n",
    "We also use the Wikimedia Foundation REST API which has the following\n",
    "terms of use:\n",
    "https://www.mediawiki.org/wiki/REST_API#Terms_and_conditions\n",
    "\n",
    "The Pageviews API documentation can be found at the following link:\n",
    "https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews\n",
    "\n",
    "We will leverage code developed by Dr. David W. McDonald for use in Data 512  which is provided under Creative Commons CC-BY license. (https://creativecommons.org/ and https://creativecommons.org/licenses/by/4.0/)\n",
    "\n",
    "Additionally, we will be using a list of Academy Award winning article titles provided by Dr. McDonald. A link to the list can be found here: https://drive.google.com/drive/folders/1lPJF73GX5Vyu2uAvT5VpAY-xGwP2fCCx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6964bee",
   "metadata": {},
   "source": [
    "## API Pull Setup\n",
    "\n",
    "The following sections of code will create a method to call the Pageviews API. The code was taken from Dr. McDonald's scripts noted in the Program Overview section above. Limited changes were made to lower-case variable names, update the range of dates for information pulls, and to limit line length where possible.\n",
    "\n",
    "We begin by importing the necessary Python libraries. Users may not have \"requests\" installed, and can use pip to add it to their machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17dc4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import python libraries\n",
    "import json\n",
    "import time\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d981ecd",
   "metadata": {},
   "source": [
    "The following code will create constants leveraged in the API calls in addition to a list of test article titles to verify the code is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5dca299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of constants leveraged in API calls\n",
    "\n",
    "# The REST API 'pageviews' URL - this is the common URL/endpoint for all 'pageviews' API requests\n",
    "api_request_pageviews_endpoint = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/'\n",
    "\n",
    "\n",
    "# This is a parameterized string that specifies what kind of pageviews request we are going to make\n",
    "# In this case it will be a 'per-article' based request. The string is a format string so that we can\n",
    "# replace each parameter with an appropriate value before making the request\n",
    "api_request_per_article_params = 'per-article/{project}/{access}/{agent}/{article}/{granularity}/{start}/{end}'\n",
    "\n",
    "# The Pageviews API asks that we not exceed 100 requests per second, we add a small delay to each request\n",
    "api_latency_assumed = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "api_throttle_wait = (1.0/100.0)-api_latency_assumed\n",
    "\n",
    "# When making a request to the Wikimedia API they ask that you include your email address which will allow them\n",
    "# to contact you if something happens - such as - your code exceeding rate limits - or some other error \n",
    "request_headers = {\n",
    "    'User-Agent': 'ekrolen@uw.edu, University of Washington, MSDS DATA 512 - AUTUMN 2023',\n",
    "}\n",
    "\n",
    "# This is just a list of English Wikipedia article titles that we can use for example requests\n",
    "ex_article_titles = [ 'Bison', 'Northern flicker', 'Red squirrel', 'Chinook salmon', 'Horseshoe bat' ]\n",
    "\n",
    "# This template is used to map parameter values into the API_REQUST_PER_ARTICLE_PARAMS portion of an API request. \n",
    "# The dictionary has a field/key for each of the required parameters. In the example, below, we only vary the article name,\n",
    "# so the majority of the fields can stay constant for each request. Of course, these values *could* be changed if necessary.\n",
    "article_pageviews_params_template = {\n",
    "    \"project\":     \"en.wikipedia.org\",\n",
    "    \"access\":      \"\",      # this should be changed for the different access types\n",
    "    \"agent\":       \"user\",\n",
    "    \"article\":     \"\",             # this value will be set/changed before each request\n",
    "    \"granularity\": \"monthly\",\n",
    "    \"start\":       \"2015070100\",   # July 1, 2015 in YYYYMMDDHH format\n",
    "    \"end\":         \"2023093000\"    # September 30, 2023 in YYYYMMDDHH format\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764cc9a8",
   "metadata": {},
   "source": [
    "As described in Dr. McDonald's code, \"The API request will be made using one procedure. The idea is to make this reusable. The procedure is parameterized, but relies on the constants above for the important parameters. The underlying assumption is that this will be used to request data for a set of article pages. Therefore the parameter most likely to change is the article_title.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992d7676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the api request \n",
    "\n",
    "def request_pageviews_per_article(article_title = None, \n",
    "                                  access_method = None,\n",
    "                                  endpoint_url = api_request_pageviews_endpoint, \n",
    "                                  endpoint_params = api_request_per_article_params,\n",
    "                                  request_template = article_pageviews_params_template,\n",
    "                                  headers = request_headers):\n",
    "\n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['article'] = article_title\n",
    "\n",
    "    if not request_template['article']:\n",
    "        raise Exception(\"Must supply an article title to make a pageviews request.\")\n",
    "\n",
    "    # Titles are supposed to have spaces replaced with \"_\" and be URL encoded\n",
    "    article_title_encoded = urllib.parse.quote(request_template['article'].replace(' ','_'))\n",
    "    request_template['article'] = article_title_encoded\n",
    "    \n",
    "    #Access method can also be a parameter in the call or in the request_template\n",
    "    if access_method:\n",
    "        request_template['access'] = access_method\n",
    "    \n",
    "    if not request_template['access']:\n",
    "        raise Exception(\"Must supply an access method ('desktop', 'mobile-app', or 'mobile-web') to make a pageviews request.\")\n",
    "    \n",
    "    # now, create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_params.format(**request_template)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or other community sources\n",
    "        if api_throttle_wait > 0.0:\n",
    "            time.sleep(api_throttle_wait)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075e08b",
   "metadata": {},
   "source": [
    "The following code can be uncommented to verify the API call is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3957348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Getting pageview data for: \",ex_article_titles[1])\\nviews = request_pageviews_per_article(ex_article_titles[1], \"mobile-app\")\\n\\n#print(json.dumps(views,indent=4))\\nprint(\"Have %d months of pageview data\"%(len(views[\\'items\\'])))\\nfor month in views[\\'items\\']:\\n    print(json.dumps(month,indent=4))'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(\"Getting pageview data for: \",ex_article_titles[1])\n",
    "views = request_pageviews_per_article(ex_article_titles[1], \"mobile-app\")\n",
    "\n",
    "#print(json.dumps(views,indent=4))\n",
    "print(\"Have %d months of pageview data\"%(len(views['items'])))\n",
    "for month in views['items']:\n",
    "    print(json.dumps(month,indent=4))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60b7bc",
   "metadata": {},
   "source": [
    "The following section of code will build the list of articles we want to retrieve data for. See the Program Overview section for more information on the source of this list. \n",
    "\n",
    "thank_the_academy.AUG.2023.csv should be downloaded from https://docs.google.com/spreadsheets/d/1A1h_7KAo7KXaVxdScJmIVPTvjb3IuY9oZhNV4ZHxrxw/edit#gid=1229854301 and saved to this repository's \"raw_data\" directory before running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efd78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe from the csv\n",
    "article_title_list = pd.read_csv('../raw_data/thank_the_academy.AUG.2023.csv')\n",
    "\n",
    "#Save the names as a list\n",
    "article_titles = list(article_title_list['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ce6b2",
   "metadata": {},
   "source": [
    "## Acquire monthly mobile app access data\n",
    "\n",
    "The following section of code will acquire monthly mobile app access data using the request_pageviews_per_article method and list of article titles built previously. The outputs are stored in a dictionary where the key is the article name (movie title) and the values are the timeseries data as returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5293c98c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1359 have been written\n",
      "10 of 1359 have been written\n",
      "20 of 1359 have been written\n",
      "30 of 1359 have been written\n",
      "40 of 1359 have been written\n",
      "50 of 1359 have been written\n",
      "60 of 1359 have been written\n",
      "70 of 1359 have been written\n",
      "80 of 1359 have been written\n",
      "90 of 1359 have been written\n",
      "100 of 1359 have been written\n",
      "110 of 1359 have been written\n",
      "120 of 1359 have been written\n",
      "130 of 1359 have been written\n",
      "140 of 1359 have been written\n",
      "150 of 1359 have been written\n",
      "160 of 1359 have been written\n",
      "170 of 1359 have been written\n",
      "180 of 1359 have been written\n",
      "190 of 1359 have been written\n",
      "200 of 1359 have been written\n",
      "210 of 1359 have been written\n",
      "220 of 1359 have been written\n",
      "230 of 1359 have been written\n",
      "240 of 1359 have been written\n",
      "250 of 1359 have been written\n",
      "260 of 1359 have been written\n",
      "270 of 1359 have been written\n",
      "280 of 1359 have been written\n",
      "290 of 1359 have been written\n",
      "300 of 1359 have been written\n",
      "310 of 1359 have been written\n",
      "320 of 1359 have been written\n",
      "330 of 1359 have been written\n",
      "340 of 1359 have been written\n",
      "350 of 1359 have been written\n",
      "360 of 1359 have been written\n",
      "370 of 1359 have been written\n",
      "380 of 1359 have been written\n",
      "390 of 1359 have been written\n",
      "400 of 1359 have been written\n",
      "410 of 1359 have been written\n",
      "420 of 1359 have been written\n",
      "430 of 1359 have been written\n",
      "440 of 1359 have been written\n",
      "450 of 1359 have been written\n",
      "460 of 1359 have been written\n",
      "470 of 1359 have been written\n",
      "480 of 1359 have been written\n",
      "490 of 1359 have been written\n",
      "500 of 1359 have been written\n",
      "510 of 1359 have been written\n",
      "520 of 1359 have been written\n",
      "530 of 1359 have been written\n",
      "540 of 1359 have been written\n",
      "550 of 1359 have been written\n",
      "560 of 1359 have been written\n",
      "570 of 1359 have been written\n",
      "580 of 1359 have been written\n",
      "590 of 1359 have been written\n",
      "600 of 1359 have been written\n",
      "610 of 1359 have been written\n",
      "620 of 1359 have been written\n",
      "630 of 1359 have been written\n",
      "640 of 1359 have been written\n",
      "650 of 1359 have been written\n",
      "660 of 1359 have been written\n",
      "670 of 1359 have been written\n",
      "680 of 1359 have been written\n",
      "690 of 1359 have been written\n",
      "700 of 1359 have been written\n",
      "710 of 1359 have been written\n",
      "720 of 1359 have been written\n",
      "730 of 1359 have been written\n",
      "740 of 1359 have been written\n",
      "750 of 1359 have been written\n",
      "760 of 1359 have been written\n",
      "770 of 1359 have been written\n",
      "780 of 1359 have been written\n",
      "790 of 1359 have been written\n",
      "800 of 1359 have been written\n",
      "810 of 1359 have been written\n",
      "820 of 1359 have been written\n",
      "830 of 1359 have been written\n",
      "840 of 1359 have been written\n",
      "850 of 1359 have been written\n",
      "860 of 1359 have been written\n",
      "870 of 1359 have been written\n",
      "880 of 1359 have been written\n",
      "890 of 1359 have been written\n",
      "900 of 1359 have been written\n",
      "910 of 1359 have been written\n",
      "920 of 1359 have been written\n",
      "930 of 1359 have been written\n",
      "940 of 1359 have been written\n",
      "950 of 1359 have been written\n",
      "960 of 1359 have been written\n",
      "970 of 1359 have been written\n",
      "980 of 1359 have been written\n",
      "990 of 1359 have been written\n",
      "1000 of 1359 have been written\n",
      "1010 of 1359 have been written\n",
      "1020 of 1359 have been written\n",
      "1030 of 1359 have been written\n",
      "1040 of 1359 have been written\n",
      "1050 of 1359 have been written\n",
      "1060 of 1359 have been written\n",
      "1070 of 1359 have been written\n",
      "1080 of 1359 have been written\n",
      "1090 of 1359 have been written\n",
      "1100 of 1359 have been written\n",
      "1110 of 1359 have been written\n",
      "1120 of 1359 have been written\n",
      "1130 of 1359 have been written\n",
      "1140 of 1359 have been written\n",
      "1150 of 1359 have been written\n",
      "1160 of 1359 have been written\n",
      "1170 of 1359 have been written\n",
      "1180 of 1359 have been written\n",
      "1190 of 1359 have been written\n",
      "1200 of 1359 have been written\n",
      "1210 of 1359 have been written\n",
      "1220 of 1359 have been written\n",
      "1230 of 1359 have been written\n",
      "1240 of 1359 have been written\n",
      "1250 of 1359 have been written\n",
      "1260 of 1359 have been written\n",
      "1270 of 1359 have been written\n",
      "1280 of 1359 have been written\n",
      "1290 of 1359 have been written\n",
      "1300 of 1359 have been written\n",
      "1310 of 1359 have been written\n",
      "1320 of 1359 have been written\n",
      "1330 of 1359 have been written\n",
      "1340 of 1359 have been written\n",
      "1350 of 1359 have been written\n"
     ]
    }
   ],
   "source": [
    "#Pulling the monthly mobile-app views for each article in the list\n",
    "mobile_app_dict = {}\n",
    "missing_titles = []\n",
    "for i in range(len(article_titles)):\n",
    "    if '/' in article_titles[i]:\n",
    "        missing_titles.append(article_titles[i])\n",
    "    else:\n",
    "        views = request_pageviews_per_article(article_titles[i], 'mobile-app')\n",
    "        mobile_app_dict[article_titles[i]] = views['items']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f04c5e",
   "metadata": {},
   "source": [
    "Next we will print out any article titles which could not be parsed by the Pageviews API due to a \"/\" present in their name. These articles will be omitted from our analysis as their information cannot be pulled using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae584e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\n",
      "['Victor/Victoria']\n"
     ]
    }
   ],
   "source": [
    "print(\"The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\")\n",
    "print(missing_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709bee6e",
   "metadata": {},
   "source": [
    "We will now save the mobile-app pageview information in a JSON for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b3cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making mobile_app_json a JSON\n",
    "mobile_app_json_object = json.dumps(mobile_app_dict, indent = 4) \n",
    "\n",
    "#Writing to the file\n",
    "with open('../raw_data/mobile_app_pageviews.json', 'w') as outfile:\n",
    "    outfile.write(mobile_app_json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1ac19",
   "metadata": {},
   "source": [
    "The following code verifies that the user got the full number of expected articles from the pageviews app, minus the ones which could not be pulled due to a \"/\" in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b47718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct number of articles captured in pageviews.\n"
     ]
    }
   ],
   "source": [
    "#Testing if the # of keys in the mobile_app_json is equal to the number of article titles minus the titles which\n",
    "#could not be pulled\n",
    "if len(mobile_app_dict.keys()) == len(article_titles) - len(missing_titles):\n",
    "    print(\"Correct number of articles captured in pageviews.\")\n",
    "else:\n",
    "    print(\"ERROR - wrong number of articles captured in pageviews. Expecting \"+str(len(article_titles) - len(missing_titles))+\n",
    "         \" and got: \"+str(len(mobile_app_dict.keys()))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466c5c5",
   "metadata": {},
   "source": [
    "## Acquire monthly mobile web access data\n",
    "\n",
    "The following section of code will acquire monthly mobile web access data using the request_pageviews_per_article method and list of article titles built previously. The outputs are stored in a dictionary where the key is the article name (movie title) and the values are the timeseries data as returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0850b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1359 have been written\n",
      "10 of 1359 have been written\n",
      "20 of 1359 have been written\n",
      "30 of 1359 have been written\n",
      "40 of 1359 have been written\n",
      "50 of 1359 have been written\n",
      "60 of 1359 have been written\n",
      "70 of 1359 have been written\n",
      "80 of 1359 have been written\n",
      "90 of 1359 have been written\n",
      "100 of 1359 have been written\n",
      "110 of 1359 have been written\n",
      "120 of 1359 have been written\n",
      "130 of 1359 have been written\n",
      "140 of 1359 have been written\n",
      "150 of 1359 have been written\n",
      "160 of 1359 have been written\n",
      "170 of 1359 have been written\n",
      "180 of 1359 have been written\n",
      "190 of 1359 have been written\n",
      "200 of 1359 have been written\n",
      "210 of 1359 have been written\n",
      "220 of 1359 have been written\n",
      "230 of 1359 have been written\n",
      "240 of 1359 have been written\n",
      "250 of 1359 have been written\n",
      "260 of 1359 have been written\n",
      "270 of 1359 have been written\n",
      "280 of 1359 have been written\n",
      "290 of 1359 have been written\n",
      "300 of 1359 have been written\n",
      "310 of 1359 have been written\n",
      "320 of 1359 have been written\n",
      "330 of 1359 have been written\n",
      "340 of 1359 have been written\n",
      "350 of 1359 have been written\n",
      "360 of 1359 have been written\n",
      "370 of 1359 have been written\n",
      "380 of 1359 have been written\n",
      "390 of 1359 have been written\n",
      "400 of 1359 have been written\n",
      "410 of 1359 have been written\n",
      "420 of 1359 have been written\n",
      "430 of 1359 have been written\n",
      "440 of 1359 have been written\n",
      "450 of 1359 have been written\n",
      "460 of 1359 have been written\n",
      "470 of 1359 have been written\n",
      "480 of 1359 have been written\n",
      "490 of 1359 have been written\n",
      "500 of 1359 have been written\n",
      "510 of 1359 have been written\n",
      "520 of 1359 have been written\n",
      "530 of 1359 have been written\n",
      "540 of 1359 have been written\n",
      "550 of 1359 have been written\n",
      "560 of 1359 have been written\n",
      "570 of 1359 have been written\n",
      "580 of 1359 have been written\n",
      "590 of 1359 have been written\n",
      "600 of 1359 have been written\n",
      "610 of 1359 have been written\n",
      "620 of 1359 have been written\n",
      "630 of 1359 have been written\n",
      "640 of 1359 have been written\n",
      "650 of 1359 have been written\n",
      "660 of 1359 have been written\n",
      "670 of 1359 have been written\n",
      "680 of 1359 have been written\n",
      "690 of 1359 have been written\n",
      "700 of 1359 have been written\n",
      "710 of 1359 have been written\n",
      "720 of 1359 have been written\n",
      "730 of 1359 have been written\n",
      "740 of 1359 have been written\n",
      "750 of 1359 have been written\n",
      "760 of 1359 have been written\n",
      "770 of 1359 have been written\n",
      "780 of 1359 have been written\n",
      "790 of 1359 have been written\n",
      "800 of 1359 have been written\n",
      "810 of 1359 have been written\n",
      "820 of 1359 have been written\n",
      "830 of 1359 have been written\n",
      "840 of 1359 have been written\n",
      "850 of 1359 have been written\n",
      "860 of 1359 have been written\n",
      "870 of 1359 have been written\n",
      "880 of 1359 have been written\n",
      "890 of 1359 have been written\n",
      "900 of 1359 have been written\n",
      "910 of 1359 have been written\n",
      "920 of 1359 have been written\n",
      "930 of 1359 have been written\n",
      "940 of 1359 have been written\n",
      "950 of 1359 have been written\n",
      "960 of 1359 have been written\n",
      "970 of 1359 have been written\n",
      "980 of 1359 have been written\n",
      "990 of 1359 have been written\n",
      "1000 of 1359 have been written\n",
      "1010 of 1359 have been written\n",
      "1020 of 1359 have been written\n",
      "1030 of 1359 have been written\n",
      "1040 of 1359 have been written\n",
      "1050 of 1359 have been written\n",
      "1060 of 1359 have been written\n",
      "1070 of 1359 have been written\n",
      "1080 of 1359 have been written\n",
      "1090 of 1359 have been written\n",
      "1100 of 1359 have been written\n",
      "1110 of 1359 have been written\n",
      "1120 of 1359 have been written\n",
      "1130 of 1359 have been written\n",
      "1140 of 1359 have been written\n",
      "1150 of 1359 have been written\n",
      "1160 of 1359 have been written\n",
      "1170 of 1359 have been written\n",
      "1180 of 1359 have been written\n",
      "1190 of 1359 have been written\n",
      "1200 of 1359 have been written\n",
      "1210 of 1359 have been written\n",
      "1220 of 1359 have been written\n",
      "1230 of 1359 have been written\n",
      "1240 of 1359 have been written\n",
      "1250 of 1359 have been written\n",
      "1260 of 1359 have been written\n",
      "1270 of 1359 have been written\n",
      "1280 of 1359 have been written\n",
      "1290 of 1359 have been written\n",
      "1300 of 1359 have been written\n",
      "1310 of 1359 have been written\n",
      "1320 of 1359 have been written\n",
      "1330 of 1359 have been written\n",
      "1340 of 1359 have been written\n",
      "1350 of 1359 have been written\n"
     ]
    }
   ],
   "source": [
    "#Pulling the monthly mobile-web views for each article in the list\n",
    "mobile_web_dict = {}\n",
    "missing_mobile_web_titles = []\n",
    "for i in range(len(article_titles)):\n",
    "    if '/' in article_titles[i]:\n",
    "        missing_mobile_web_titles.append(article_titles[i])\n",
    "    else:\n",
    "        views = request_pageviews_per_article(article_titles[i], 'mobile-web')\n",
    "        mobile_web_dict[article_titles[i]] = views['items']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34baa3f3",
   "metadata": {},
   "source": [
    "Next we will print out any article titles which could not be parsed by the Pageviews API due to a \"/\" present in their name. These articles will be omitted from our analysis as their information cannot be pulled using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21726254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\n",
      "['Victor/Victoria']\n"
     ]
    }
   ],
   "source": [
    "print(\"The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\")\n",
    "print(missing_mobile_web_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c92d0a",
   "metadata": {},
   "source": [
    "We will now save the mobile-web pageview information in a JSON for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3e94249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making mobile_web_json a JSON\n",
    "mobile_web_json_object = json.dumps(mobile_web_dict, indent = 4) \n",
    "\n",
    "#Writing to the file\n",
    "with open('../raw_data/mobile_web_pageviews.json', 'w') as outfile:\n",
    "    outfile.write(mobile_web_json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05422585",
   "metadata": {},
   "source": [
    "The following code verifies that the user got the full number of expected articles from the pageviews app, minus the ones which could not be pulled due to a \"/\" in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebce72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct number of articles captured in pageviews.\n"
     ]
    }
   ],
   "source": [
    "#Testing if the # of keys in the mobile_web_dict is equal to the number of article titles minus the titles which\n",
    "#could not be pulled\n",
    "if len(mobile_web_dict.keys()) == len(article_titles) - len(missing_mobile_web_titles):\n",
    "    print(\"Correct number of articles captured in pageviews.\")\n",
    "else:\n",
    "    print(\"ERROR - wrong number of articles captured in pageviews. Expecting \"+\n",
    "          str(len(article_titles) - len(missing_mobile_web_titles))+\" and got: \"+str(len(mobile_web_dict.keys()))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3bd59",
   "metadata": {},
   "source": [
    "## Acquire desktop access data\n",
    "\n",
    "The following section of code will acquire monthly desktop access data using the request_pageviews_per_article method and list of article titles built previously. The outputs are stored in a dictionary where the key is the article name (movie title) and the values are the timeseries data as returned by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c31bfb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1359 have been written\n",
      "10 of 1359 have been written\n",
      "20 of 1359 have been written\n",
      "30 of 1359 have been written\n",
      "40 of 1359 have been written\n",
      "50 of 1359 have been written\n",
      "60 of 1359 have been written\n",
      "70 of 1359 have been written\n",
      "80 of 1359 have been written\n",
      "90 of 1359 have been written\n",
      "100 of 1359 have been written\n",
      "110 of 1359 have been written\n",
      "120 of 1359 have been written\n",
      "130 of 1359 have been written\n",
      "140 of 1359 have been written\n",
      "150 of 1359 have been written\n",
      "160 of 1359 have been written\n",
      "170 of 1359 have been written\n",
      "180 of 1359 have been written\n",
      "190 of 1359 have been written\n",
      "200 of 1359 have been written\n",
      "210 of 1359 have been written\n",
      "220 of 1359 have been written\n",
      "230 of 1359 have been written\n",
      "240 of 1359 have been written\n",
      "250 of 1359 have been written\n",
      "260 of 1359 have been written\n",
      "270 of 1359 have been written\n",
      "280 of 1359 have been written\n",
      "290 of 1359 have been written\n",
      "300 of 1359 have been written\n",
      "310 of 1359 have been written\n",
      "320 of 1359 have been written\n",
      "330 of 1359 have been written\n",
      "340 of 1359 have been written\n",
      "350 of 1359 have been written\n",
      "360 of 1359 have been written\n",
      "370 of 1359 have been written\n",
      "380 of 1359 have been written\n",
      "390 of 1359 have been written\n",
      "400 of 1359 have been written\n",
      "410 of 1359 have been written\n",
      "420 of 1359 have been written\n",
      "430 of 1359 have been written\n",
      "440 of 1359 have been written\n",
      "450 of 1359 have been written\n",
      "460 of 1359 have been written\n",
      "470 of 1359 have been written\n",
      "480 of 1359 have been written\n",
      "490 of 1359 have been written\n",
      "500 of 1359 have been written\n",
      "510 of 1359 have been written\n",
      "520 of 1359 have been written\n",
      "530 of 1359 have been written\n",
      "540 of 1359 have been written\n",
      "550 of 1359 have been written\n",
      "560 of 1359 have been written\n",
      "570 of 1359 have been written\n",
      "580 of 1359 have been written\n",
      "590 of 1359 have been written\n",
      "600 of 1359 have been written\n",
      "610 of 1359 have been written\n",
      "620 of 1359 have been written\n",
      "630 of 1359 have been written\n",
      "640 of 1359 have been written\n",
      "650 of 1359 have been written\n",
      "660 of 1359 have been written\n",
      "670 of 1359 have been written\n",
      "680 of 1359 have been written\n",
      "690 of 1359 have been written\n",
      "700 of 1359 have been written\n",
      "710 of 1359 have been written\n",
      "720 of 1359 have been written\n",
      "730 of 1359 have been written\n",
      "740 of 1359 have been written\n",
      "750 of 1359 have been written\n",
      "760 of 1359 have been written\n",
      "770 of 1359 have been written\n",
      "780 of 1359 have been written\n",
      "790 of 1359 have been written\n",
      "800 of 1359 have been written\n",
      "810 of 1359 have been written\n",
      "820 of 1359 have been written\n",
      "830 of 1359 have been written\n",
      "840 of 1359 have been written\n",
      "850 of 1359 have been written\n",
      "860 of 1359 have been written\n",
      "870 of 1359 have been written\n",
      "880 of 1359 have been written\n",
      "890 of 1359 have been written\n",
      "900 of 1359 have been written\n",
      "910 of 1359 have been written\n",
      "920 of 1359 have been written\n",
      "930 of 1359 have been written\n",
      "940 of 1359 have been written\n",
      "950 of 1359 have been written\n",
      "960 of 1359 have been written\n",
      "970 of 1359 have been written\n",
      "980 of 1359 have been written\n",
      "990 of 1359 have been written\n",
      "1000 of 1359 have been written\n",
      "1010 of 1359 have been written\n",
      "1020 of 1359 have been written\n",
      "1030 of 1359 have been written\n",
      "1040 of 1359 have been written\n",
      "1050 of 1359 have been written\n",
      "1060 of 1359 have been written\n",
      "1070 of 1359 have been written\n",
      "1080 of 1359 have been written\n",
      "1090 of 1359 have been written\n",
      "1100 of 1359 have been written\n",
      "1110 of 1359 have been written\n",
      "1120 of 1359 have been written\n",
      "1130 of 1359 have been written\n",
      "1140 of 1359 have been written\n",
      "1150 of 1359 have been written\n",
      "1160 of 1359 have been written\n",
      "1170 of 1359 have been written\n",
      "1180 of 1359 have been written\n",
      "1190 of 1359 have been written\n",
      "1200 of 1359 have been written\n",
      "1210 of 1359 have been written\n",
      "1220 of 1359 have been written\n",
      "1230 of 1359 have been written\n",
      "1240 of 1359 have been written\n",
      "1250 of 1359 have been written\n",
      "1260 of 1359 have been written\n",
      "1270 of 1359 have been written\n",
      "1280 of 1359 have been written\n",
      "1290 of 1359 have been written\n",
      "1300 of 1359 have been written\n",
      "1310 of 1359 have been written\n",
      "1320 of 1359 have been written\n",
      "1330 of 1359 have been written\n",
      "1340 of 1359 have been written\n",
      "1350 of 1359 have been written\n"
     ]
    }
   ],
   "source": [
    "#Pulling the monthly desktop views for each article in the list\n",
    "desktop_dict = {}\n",
    "missing_desktop_titles = []\n",
    "for i in range(len(article_titles)):\n",
    "    if '/' in article_titles[i]:\n",
    "        missing_desktop_titles.append(article_titles[i])\n",
    "    else:\n",
    "        views = request_pageviews_per_article(article_titles[i], 'desktop')\n",
    "        desktop_dict[article_titles[i]] = views['items']\n",
    "    if i%10 == 0:\n",
    "        print(str(i)+\" of \"+str(len(article_titles))+\" have been written\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be300c52",
   "metadata": {},
   "source": [
    "Next we will print out any article titles which could not be parsed by the Pageviews API due to a \"/\" present in their name. These articles will be omitted from our analysis as their information cannot be pulled using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3472707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\n",
      "['Victor/Victoria']\n"
     ]
    }
   ],
   "source": [
    "print(\"The following titles were unable to be parsed by the Pageviews API and will not be included in future analysis:\")\n",
    "print(missing_desktop_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a7d4c",
   "metadata": {},
   "source": [
    "We will now save the desktop pageview information in a JSON for future processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4becc118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making desktop_json a JSON\n",
    "desktop_json_object = json.dumps(desktop_dict, indent = 4) \n",
    "\n",
    "#Writing to the file\n",
    "with open('../raw_data/desktop_pageviews.json', 'w') as outfile:\n",
    "    outfile.write(desktop_json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20768c",
   "metadata": {},
   "source": [
    "The following code verifies that the user got the full number of expected articles from the pageviews app, minus the ones which could not be pulled due to a \"/\" in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65d0ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct number of articles captured in pageviews.\n"
     ]
    }
   ],
   "source": [
    "#Testing if the # of keys in the desktop_dict is equal to the number of article titles minus the titles which\n",
    "#could not be pulled\n",
    "if len(desktop_dict.keys()) == len(article_titles) - len(missing_desktop_titles):\n",
    "    print(\"Correct number of articles captured in pageviews.\")\n",
    "else:\n",
    "    print(\"ERROR - wrong number of articles captured in pageviews. Expecting \"+\n",
    "          str(len(article_titles) - len(missing_desktop_titles))+\" and got: \"+str(len(desktop_dict.keys()))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
